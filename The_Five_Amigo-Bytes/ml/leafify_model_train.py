"""leafify_model_complete.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lkAKlq6pyRN74WV04EhCW4NbuuRt8Z9C
"""

from google.colab import drive
drive.mount('/content/drive')

import kagglehub
path = kagglehub.dataset_download("vipoooool/new-plant-diseases-dataset")
path = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)"
train = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train"
valid = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid"
test  = "/kaggle/input/new-plant-diseases-dataset/test"

import warnings
warnings.filterwarnings('ignore')

import os
import json
import pickle

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import torchvision
from torchvision import transforms
from torchvision.datasets import ImageFolder

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

from tqdm import tqdm
!pip install colorama
import colorama
from colorama import Fore, Style
!pip install torchinfo

import matplotlib.pyplot as plt
import random
import os
from PIL import Image
import numpy as np
import kagglehub
Diseases_classes = os.listdir(train)
def display_disease_samples(data_dir, plants=None, num_cols=5):
    disease_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])

    if plants is not None:
        disease_folders = [f for f in disease_folders if any(p in f for p in plants)]

    num_diseases = len(disease_folders)
    num_rows = (num_diseases + num_cols - 1) // num_cols
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 4 * num_rows))
    axes = axes.flatten() if num_rows > 1 else axes

    for i, disease_folder in enumerate(disease_folders):
        folder_path = os.path.join(data_dir, disease_folder)

        img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if img_files:
            img_path = os.path.join(folder_path, random.choice(img_files))
            img = Image.open(img_path).convert('RGB')

            disease_name = disease_folder.replace('_', ' ')

            axes[i].imshow(img)
            axes[i].set_title(disease_name, fontsize=12)
            axes[i].axis('off')

    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()

print("üåø Sample images from different plant disease categories:")
display_disease_samples(test)

Root_dir = path
train_dir = Root_dir + "/train"
valid_dir = Root_dir + "/valid"
test_dir = test
Diseases_classes = os.listdir(train_dir)
print(Fore.GREEN +str(Diseases_classes))
print("\nTotal number of classes are: ", len(Diseases_classes))
plt.figure(figsize=(60,60), dpi=200)
cnt = 0
plant_names = []
tot_images = 0

for i in Diseases_classes:
    cnt += 1
    plant_names.append(i)
    plt.subplot(7,7,cnt)

    image_path = os.listdir(train_dir + "/" + i)
    print(Fore.GREEN)
    print("The Number of Images in " +i+ ":", len(image_path), end= " ")
    tot_images += len(image_path)

    img_show = plt.imread(train_dir + "/" + i + "/" + image_path[0])

    plt.imshow(img_show)
    plt.xlabel(i,fontsize=30)
    plt.xticks([])
    plt.yticks([])


print("\nTotal Number of Images in Directory: ", tot_images)

class PlantDiseaseDataset(Dataset):
    """Custom Dataset for loading plant disease images"""
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        img = Image.open(img_path).convert("RGB")
        if self.transform:
            img = self.transform(img)

        return img, torch.tensor(label, dtype=torch.long)

from torchinfo import summary

class PlantDiseaseModel(nn.Module):
    """Convolutional Neural Network for plant disease classification"""
    def __init__(self, num_classes, dropout_rate=0.5):
        super(PlantDiseaseModel, self).__init__()
        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding="same"),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.conv_block2 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding="same"),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.conv_block3 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding="same"),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )

        self.conv_block4 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, padding="same"),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.conv_block5 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, padding="same"),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc_block = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = self.conv_block3(x)
        x = self.conv_block4(x)
        x = self.conv_block5(x)
        x = self.global_avg_pool(x)
        x = self.fc_block(x)
        return x

print(summary(PlantDiseaseModel(15), input_size=(1, 3, 224, 224)))

class EarlyStopping:
    """Early stopping handler to prevent overfitting"""
    def __init__(self, patience=5, min_delta=0.001, save_path="best_model.pth"):
        self.patience = patience
        self.min_delta = min_delta
        self.save_path = save_path
        self.best_loss = float('inf')
        self.counter = 0

    def __call__(self, val_loss, model):
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            torch.save(model.state_dict(), self.save_path)
            print(f"[INFO] Model checkpoint saved to {self.save_path}")
            return False
        else:
            self.counter += 1
            if self.counter >= self.patience:
                print("[INFO] Early stopping triggered.")
                return True
        return False

from torchvision.datasets import ImageFolder
from torchvision import transforms

train = train
valid = valid

train = ImageFolder(train, transform=transforms.ToTensor())
valid = ImageFolder(valid, transform=transforms.ToTensor())

train

train[0]

train[7000]

train[70000]

img, label = train[0]
print(img.shape, label)

def show_augmentations(data_dir, num_plants=3):
    disease_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]
    selected_folders = random.sample(disease_folders, min(num_plants, len(disease_folders)))
    augmentations = [
        ("Original", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor()
        ])),
        ("Horizontal Flip", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor()
        ])),
        ("Rotation (30¬∞)", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomRotation(30),
            transforms.ToTensor()
        ])),
        ("Color Jitter", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.ToTensor()
        ])),
        ("Combined", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(20),
            transforms.ColorJitter(brightness=0.1, contrast=0.1),
            transforms.ToTensor()
        ]))
    ]

    fig, axes = plt.subplots(len(selected_folders), len(augmentations), figsize=(18, 4 * len(selected_folders)))

    for i, folder in enumerate(selected_folders):
        folder_path = os.path.join(data_dir, folder)

        img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if not img_files:
            continue

        img_path = os.path.join(folder_path, random.choice(img_files))
        original_img = Image.open(img_path).convert('RGB')

        for j, (aug_name, transform) in enumerate(augmentations):
            img_tensor = transform(original_img)

            img_np = img_tensor.permute(1, 2, 0).numpy()

            ax = axes[i, j] if len(selected_folders) > 1 else axes[j]
            ax.imshow(img_np)

            if i == 0:
                ax.set_title(aug_name, fontsize=12)

            if j == 0:
                disease_name = folder.replace('_', ' ')
                ax.set_ylabel(disease_name, fontsize=10)

            ax.axis('off')

    plt.tight_layout()
    plt.suptitle("Data Augmentation Techniques for Plant Disease Images", fontsize=20, y=1.0)
    plt.show()

show_augmentations(test)

def show_image(image, label):
    print("Label :" + train.classes[label] + "(" + str(label) + ")")
    plt.imshow(image.permute(1, 2, 0))


image_list = [0, 3000, 5000, 8000, 12000, 15000, 60000, 70000]

chs = 0
for img in image_list:
    chs += 1
    plt.subplot(2,4,chs)
    print(Fore.GREEN)
    plt.tight_layout()
    plt.xlabel(img,fontsize=10)
    plt.title(train[img][1])
    show_image(*train[img])

batch_size = 32

train_dataloader = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)
valid_dataloader = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)

def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available:
        return torch.device("cuda")
    else:
        return torch.device("cpu")
def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dataloader, device):
        self.dataloader = dataloader
        self.device = device

    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dataloader:
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dataloader)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device
train_dataloader = DeviceDataLoader(train_dataloader, device)
valid_dataloader = DeviceDataLoader(valid_dataloader, device)

def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

class ImageClassificationBase(nn.Module):

    def training_step(self, batch):
        images, labels = batch
        out = self(images)                
        loss = F.cross_entropy(out, labels) 
        return loss

    def validation_step(self, batch):
        images, labels = batch
        out = self(images)                    
        loss = F.cross_entropy(out, labels)   
        acc = accuracy(out, labels)
        return {'val_loss': loss.detach(), 'val_acc': acc}

    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}

    def epoch_end(self, epoch, result):
        print("Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
            epoch, result['train_loss'], result['val_loss'], result['val_acc']))

def ConvBlock(in_channels, out_channels, pool=False):
    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
             nn.BatchNorm2d(out_channels),
             nn.ReLU(inplace=True)]
    if pool:
        layers.append(nn.MaxPool2d(4))
    return nn.Sequential(*layers)

class CNN_NeuralNet(ImageClassificationBase):
    def __init__(self, in_channels, num_diseases):
        super().__init__()

        self.conv1 = ConvBlock(in_channels, 64)
        self.conv2 = ConvBlock(64, 128, pool=True)
        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))

        self.conv3 = ConvBlock(128, 256, pool=True)
        self.conv4 = ConvBlock(256, 512, pool=True)

        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))
        self.classifier = nn.Sequential(nn.MaxPool2d(4),
                                       nn.Flatten(),
                                       nn.Linear(512, num_diseases))

    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out = self.res1(out) + out
        out = self.conv3(out)
        out = self.conv4(out)
        out = self.res2(out) + out
        out = self.classifier(out)
        return out

model = to_device(CNN_NeuralNet(3, len(train.classes)), device)
model

# for training
@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)
def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']

def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,
                grad_clip=None, opt_func=torch.optim.SGD):
    torch.cuda.empty_cache()
    history = []  

    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)
    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr,
                                                epochs=epochs, steps_per_epoch=len(train_loader))


    for epoch in range(epochs):
        model.train()
        train_losses = []
        lrs = []
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            if grad_clip:
                nn.utils.clip_grad_value_(model.parameters(), grad_clip)

            optimizer.step()
            optimizer.zero_grad()
            lrs.append(get_lr(optimizer))
            sched.step()

        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        result['lrs'] = lrs
        model.epoch_end(epoch, result)
        history.append(result)

    return history

def evaluate_by_plant_type(model, test_loader, label_encoder, device):
    """Evaluate model performance separately for each plant type with enhanced visualization"""
    model.eval()
    class_correct = {}
    class_total = {}
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            for i, label in enumerate(labels):
                label_idx = label.item()
                label_name = label_encoder.inverse_transform([label_idx])[0]

                if label_name not in class_correct:
                    class_correct[label_name] = 0
                    class_total[label_name] = 0

                class_total[label_name] += 1
                if preds[i] == label:
                    class_correct[label_name] += 1

    plants = {}
    for class_name in class_correct.keys():
        if "__" in class_name:
            plant = class_name.split("__")[0].replace("_", " ")
        else:
            plant = class_name.split("_")[0]

        if plant not in plants:
            plants[plant] = {"correct": 0, "total": 0}

        plants[plant]["correct"] += class_correct[class_name]
        plants[plant]["total"] += class_total[class_name]

    plant_accuracy = {p: (stats["correct"] / stats["total"]) * 100
                     for p, stats in plants.items()}

    sorted_plants = dict(sorted(plant_accuracy.items(), key=lambda x: x[1], reverse=True))

    plt.style.use('ggplot')
    fig = plt.figure(figsize=(16, 10))
    ax = fig.add_subplot(111)


    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(sorted_plants)))


    avg_accuracy = np.mean(list(plant_accuracy.values()))

    plants_list = list(sorted_plants.keys())
    accuracies = list(sorted_plants.values())
    totals = [plants[p]["total"] for p in plants_list]

    ax.set_facecolor('#f8f9fa')
    fig.patch.set_facecolor('#ffffff')

    bars = ax.bar(plants_list, accuracies, color=colors, edgecolor='#505050',
                 linewidth=1, alpha=0.85, width=0.7)

    for bar in bars:
        x, y = bar.get_xy()
        w, h = bar.get_width(), bar.get_height()
        shadow = plt.Rectangle((x+0.03, y-0.03), w, h, color='#00000022', zorder=0)
        ax.add_patch(shadow)

    for bar, acc, total in zip(bars, accuracies, totals):
        height = bar.get_height()

        ax.text(bar.get_x() + bar.get_width()/2., height + 1,
               f'{acc:.1f}%',
               ha='center', va='bottom',
               fontsize=11, fontweight='bold',
               bbox=dict(boxstyle="round,pad=0.3", fc='white', ec="grey", alpha=0.8))

        ax.text(bar.get_x() + bar.get_width()/2., height/2,
               f'n={total}',
               ha='center', va='center',
               fontsize=10, color='#303030',
               fontweight='bold', rotation=0)
    ax.axhline(avg_accuracy, color='#e74c3c', linestyle='-', linewidth=2.5, alpha=0.7)
    ax.axhline(avg_accuracy, color='#c0392b', linestyle='-', linewidth=1, alpha=1)
    ax.text(len(plants_list)-0.5, avg_accuracy + 3,
           f' Average: {avg_accuracy:.1f}%',
           color='#c0392b', fontsize=13, ha='right', va='bottom',
           fontweight='bold',
           bbox=dict(boxstyle="round,pad=0.3", fc='white', ec="#c0392b", alpha=0.8))

    ax.set_title(f'Model Accuracy by Plant Type\n{model.__class__.__name__} Performance Analysis',
                fontsize=18, pad=20, fontweight='bold', color='#2c3e50')

    ax.set_xlabel('Plant Type', fontsize=14, labelpad=15, fontweight='bold', color='#2c3e50')
    ax.set_ylabel('Accuracy (%)', fontsize=14, labelpad=15, fontweight='bold', color='#2c3e50')

    for spine in ax.spines.values():
        spine.set_visible(True)
        spine.set_color('#cccccc')
        spine.set_linewidth(1)

    ax.tick_params(axis='x', rotation=45, labelsize=12, pad=5, colors='#2c3e50')
    ax.tick_params(axis='y', labelsize=12, pad=5, colors='#2c3e50')
    ax.set_ylim(0, max(accuracies) * 1.15)

    ax.yaxis.grid(True, linestyle='--', alpha=0.4, color='#95a5a6')
    ax.set_axisbelow(True)

    top_performer = plants_list[0]
    top_accuracy = accuracies[0]
    ax.text(0, max(accuracies) * 1.1,
           f"Top Performer: {top_performer} ({top_accuracy:.1f}%)",
           fontsize=12, ha='left', color='#27ae60',
           bbox=dict(boxstyle="round,pad=0.3", fc='#f8f9fa', ec="#2ecc71", alpha=0.8))

    fig.text(0.95, 0.02, f"{model.__class__.__name__}",
             fontsize=10, color='gray', ha='right', va='bottom', alpha=0.7)

    plt.tight_layout()
    plt.show()

    return plant_accuracy
def evaluate_model(model, data_loader, criterion, device):
    """Evaluate model on validation or test set"""
    model.eval()
    val_loss = 0.0
    correct, total = 0, 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        progress_bar = tqdm(enumerate(data_loader), desc="Evaluating", total=len(data_loader))
        for batch_idx, (inputs, labels) in progress_bar:
            inputs, labels = inputs.to(device), labels.to(device)
            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            progress_bar.set_postfix({"Val Loss": loss.item(), "Accuracy": correct / total * 100})

    val_loss /= len(data_loader)
    accuracy = correct / total * 100
    return val_loss, accuracy, np.array(all_preds), np.array(all_labels)

def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler=None,
                epochs=10, early_stopping=None, device="cpu"):
    """Train the model with optional early stopping and learning rate scheduler"""
    model.to(device)
    train_losses, valid_losses, valid_accuracies = [], [], []

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        progress_bar = tqdm(enumerate(train_loader), desc=f"Epoch {epoch+1}/{epochs}",
                           total=len(train_loader))

        for batch_idx, (inputs, labels) in progress_bar:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix({"Train Loss": loss.item()})

        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)

        val_loss, val_accuracy, _, _ = evaluate_model(model, valid_loader, criterion, device)
        valid_losses.append(val_loss)
        valid_accuracies.append(val_accuracy)

        print(f"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, "
              f"Val Accuracy = {val_accuracy:.2f}%")

        if scheduler:
            scheduler.step(val_loss)

        if early_stopping and early_stopping(val_loss, model):
            print("[INFO] Early stopping triggered.")
            break
    save_learning_curves(train_losses, valid_losses, valid_accuracies)

    return train_losses, valid_losses, valid_accuracies

def save_learning_curves(train_losses, valid_losses, valid_accuracies):
    """Save learning curves as a plot"""
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Training Loss')
    plt.plot(valid_losses, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Training and Validation Loss')

    plt.subplot(1, 2, 2)
    plt.plot(valid_accuracies, label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.title('Validation Accuracy')

    plt.tight_layout()
    plt.savefig('learning_curves.png')
    plt.close()

def predict_image(model, image_path, transform, device, label_encoder=None):
    """Make prediction on a single image"""
    model.eval()

    image = Image.open(image_path).convert("RGB")
    image_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(image_tensor)
        _, predicted = torch.max(outputs, 1)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)

    predicted_idx = predicted.item()
    confidence = probabilities[0][predicted_idx].item() * 100

    if label_encoder:
        predicted_class = label_encoder.inverse_transform([predicted_idx])[0]
        return predicted_class, confidence, probabilities[0].cpu().numpy()
    else:
        return predicted_idx, confidence, probabilities[0].cpu().numpy()

def train(data_dir, model_save_path="best_model.pth", batch_size=32,
          epochs=30, learning_rate=0.001, image_size=(256, 256)):
    """Main function to train and save the model and necessary files for deployment"""

    train_loader, valid_loader, test_loader, num_classes = prepare_data(
        data_dir, image_size=image_size, batch_size=batch_size
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    model = PlantDiseaseModel(num_classes=num_classes, dropout_rate=0.5)
    model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.1, patience=3, verbose=True
    )
    early_stopping = EarlyStopping(patience=7, min_delta=0.001, save_path=model_save_path)

    print(f"Model created with {num_classes} output classes")

    train_model(
        model=model,
        train_loader=train_loader,
        valid_loader=valid_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        epochs=epochs,
        early_stopping=early_stopping,
        device=device
    )

    model.load_state_dict(torch.load(model_save_path))

    print("\n[INFO] Evaluating the model on the test set...")
    test_loss, test_accuracy, predictions, true_labels = evaluate_model(
        model, test_loader, criterion, device
    )
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%")

    dummy_input = torch.randn(1, 3, *image_size).to(device)
    torch.onnx.export(model, dummy_input, "plant_disease_model.onnx")

    model_config = {
        "image_size": image_size,
        "num_classes": num_classes,
        "model_path": model_save_path,
        "label_encoder_path": "label_encoder.pkl",
        "transform_path": "inference_transform.pkl",
        "class_names_path": "class_names.json"
    }

    with open("model_config.json", "w") as f:
        json.dump(model_config, f)

    print("[INFO] Training completed and all necessary files saved for deployment.")
    return model, model_config

import kagglehub
path = kagglehub.dataset_download("vipoooool/new-plant-diseases-dataset")
train_dir = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train"
valid_dir = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid"
test_dir  = "/kaggle/input/new-plant-diseases-dataset/test"

import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
import time

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

train_tf = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

valid_tf = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])
train_data = datasets.ImageFolder(train_dir, transform=train_tf)
valid_data = datasets.ImageFolder(valid_dir, transform=valid_tf)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)
valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False, num_workers=2)

num_classes = len(train_data.classes)
print("Classes:", train_data.classes)
model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)


model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0005)
epochs = 8
scaler = torch.cuda.amp.GradScaler()

start = time.time()

for epoch in range(epochs):
    model.train()
    total = 0
    correct = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            outputs = model(images)
            loss = criterion(outputs, labels)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    train_acc = correct / total

    model.eval()
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for images, labels in valid_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            val_correct += (preds == labels).sum().item()
            val_total += labels.size(0)

    val_acc = val_correct / val_total

    print(f"Epoch {epoch+1}/{epochs} | "
          f"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}")

end = time.time()
print("Training time:", round(end - start, 2), "seconds")

torch.save(model.state_dict(), "fast_plant_model.pth")
print("Model saved as fast_plant_model.pth")

import os
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torch
import torch.nn.functional as F
import cv2

def apply_gradcam(model, img_path, transform, label_encoder, device, layer_name='conv_block5'):
    model.eval()

    activations = None
    gradients = None

    def forward_hook(module, input, output):
        nonlocal activations
        activations = output

    def backward_hook(module, grad_input, grad_output):
        nonlocal gradients
        gradients = grad_output[0]
    target_layer = None
    if hasattr(model, layer_name):
        target_layer = getattr(model, layer_name)
        if isinstance(target_layer, torch.nn.Sequential):
             target_layer = target_layer[-1] 
    else:
        if layer_name == 'conv_block5' and hasattr(model, 'conv_block5'):
            target_layer = model.conv_block5[0]
        elif layer_name == 'conv_block4' and hasattr(model, 'conv_block4'):
            target_layer = model.conv_block4[0]
        elif layer_name == 'conv_block3' and hasattr(model, 'conv_block3'):
            target_layer = model.conv_block3[0]

    if target_layer is None:
        print(f"Error: Layer '{layer_name}' not found in model.")
        return


    forward_handle = target_layer.register_forward_hook(forward_hook)
    backward_handle = target_layer.register_full_backward_hook(backward_hook)

    try:
        img = Image.open(img_path).convert('RGB')
        input_tensor = transform(img).unsqueeze(0).to(device)

        input_tensor.requires_grad_()

        output = model(input_tensor)
        pred_idx = output.argmax(dim=1).item()

        if hasattr(label_encoder, 'inverse_transform'):
            pred_class = label_encoder.inverse_transform([pred_idx])[0]
        else:
            pred_class = label_encoder[pred_idx] 

        model.zero_grad()

        score = output[:, pred_idx]
        score.backward()

        if activations is not None and gradients is not None:
            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])

            for i in range(activations.size(1)):
                activations[:, i, :, :] *= pooled_gradients[i]
            heatmap = torch.mean(activations, dim=1).squeeze().detach().cpu().numpy()

            heatmap = np.maximum(heatmap, 0)

            if np.max(heatmap) > 0:
                heatmap /= np.max(heatmap)
            else:
                print("Warning: Heatmap is empty (zeros).")

            original_img = np.array(img)
            heatmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))

            heatmap = np.uint8(255 * heatmap)
            heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
            superimposed = cv2.addWeighted(original_img, 0.6, cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB), 0.4, 0)
            plt.figure(figsize=(15, 5))

            plt.subplot(1, 3, 1)
            plt.imshow(original_img)
            plt.title("Original Image")
            plt.axis('off')

            plt.subplot(1, 3, 2)
            plt.imshow(cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB))
            plt.title("Grad-CAM Heatmap")
            plt.axis('off')

            plt.subplot(1, 3, 3)
            plt.imshow(superimposed)
            plt.title(f"Prediction: {pred_class}")
            plt.axis('off')

            plt.show()
        else:
            print("Could not generate activations or gradients. Check layer connection.")

    except Exception as e:
        print(f"An error occurred during Grad-CAM: {e}")
        import traceback
        traceback.print_exc()

    finally:
        forward_handle.remove()
        backward_handle.remove()

def generate_gradcam_visualizations(model, transform, label_encoder, device, data_dir, num_samples=2):
    print("\nüîç Generating Grad-CAM visualizations...")
    sample_images = []

    if not os.path.exists(data_dir):
        print(f"Error: Data directory '{data_dir}' does not exist.")
        return

    for disease_folder in os.listdir(data_dir):
        disease_folder_path = os.path.join(data_dir, disease_folder)
        if not os.path.isdir(disease_folder_path):
            continue

        img_files = [f for f in os.listdir(disease_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if img_files:
            selected_img = os.path.join(disease_folder_path, random.choice(img_files))
            sample_images.append((selected_img, disease_folder))

    if sample_images:
        samples_to_visualize = random.sample(sample_images, min(num_samples, len(sample_images)))
        for i, (img_path, true_label) in enumerate(samples_to_visualize):
            print(f"\nVisualizing sample {i+1} - True Label: {true_label}")
            apply_gradcam(model, img_path, transform, label_encoder, device, layer_name='conv_block5')
    else:
        print("No sample images found in the directory structure.")

import os
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torch
import cv2
import torchvision.models as models
def apply_gradcam_high_accuracy(model, img_path, transform, device, layer_name='conv_block5', threshold=0.4):
    model.eval()
    activations = None
    gradients = None

    # Hooks
    def forward_hook(module, input, output):
        nonlocal activations
        activations = output

    def backward_hook(module, grad_input, grad_output):
        nonlocal gradients
        gradients = grad_output[0]

    target_layer = None
    if hasattr(model, layer_name): target_layer = getattr(model, layer_name)
    elif hasattr(model, 'layer4'): target_layer = model.layer4[-1]       
    elif hasattr(model, 'features'): target_layer = model.features[-1]   
    elif hasattr(model, 'conv_block5'): target_layer = model.conv_block5[0]

    if target_layer is None:
        print(f"‚ùå Error: Could not find layer. Check model architecture.")
        return

    h1 = target_layer.register_forward_hook(forward_hook)
    h2 = target_layer.register_full_backward_hook(backward_hook)

    try:
        # Load Image
        img = Image.open(img_path).convert('RGB')
        input_tensor = transform(img).unsqueeze(0).to(device)
        input_tensor.requires_grad_()

        # Forward
        output = model(input_tensor)
        pred_idx = output.argmax(dim=1).item()
        confidence = torch.softmax(output, dim=1)[0][pred_idx].item()

        # Backward
        model.zero_grad()
        output[:, pred_idx].backward()

        if activations is None or gradients is None:
            return
        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])
        for i in range(activations.size(1)):
            activations[:, i, :, :] *= pooled_gradients[i]

        heatmap = torch.mean(activations, dim=1).squeeze().detach().cpu().numpy()
        heatmap = np.maximum(heatmap, 0) 
        if np.max(heatmap) > 0:
            heatmap /= np.max(heatmap)
        heatmap[heatmap < threshold] = 0
        original_img = np.array(img)
        heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))

        heatmap_uint8 = np.uint8(255 * heatmap_resized)
        heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
        heatmap_rgb = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB)
        mask = heatmap_resized > 0
        mask = np.stack([mask]*3, axis=-1)

        superimposed = original_img.copy()
        np.putmask(superimposed, mask, cv2.addWeighted(original_img, 0.5, heatmap_rgb, 0.5, 0))


        plt.figure(figsize=(15, 5))

        plt.subplot(1, 3, 1)
        plt.imshow(original_img)
        plt.title(f"Original")
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.imshow(heatmap_rgb)
        plt.title("Raw Heatmap (Thresholded)")
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.imshow(superimposed)
        plt.title(f"Affected Area (Conf: {confidence:.2f})")
        plt.axis('off')

        plt.tight_layout()
        plt.show()
        print(f"‚úÖ Processed: {os.path.basename(img_path)}")

    except Exception as e:
        print(f"Error: {e}")
    finally:
        h1.remove()
        h2.remove()
        
def scan_and_visualize(dataset_path, model, transform, num_images=3):
    print(f"\nüìÇ Scanning dataset at: {dataset_path}")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    all_image_paths = []

    if not os.path.exists(dataset_path):
        print(f"‚ùå Error: Path '{dataset_path}' does not exist.")
        return

    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                full_path = os.path.join(root, file)
                folder_name = os.path.basename(root)
                all_image_paths.append((full_path, folder_name))

    if not all_image_paths:
        print("‚ùå No images found!")
        return

    print(f"Found {len(all_image_paths)} images.")
    selected_samples = random.sample(all_image_paths, min(num_images, len(all_image_paths)))

    for img_path, label in selected_samples:
        print(f"\nTesting Image from: '{label}'")
        
        apply_gradcam_high_accuracy(model, img_path, transform, device, layer_name='conv_block5', threshold=0.45)
MODEL_FILE_PATH = "my_trained_model.pth"

try:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("‚ö†Ô∏è Using ResNet50 for demonstration (Replace with your own model)")
    model = models.resnet50(pretrained=True)

    print("‚úÖ Model loaded.")
except Exception as e:
    print(f"‚ùå Model Load Error: {e}")

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

DATA_DIR = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)"

if __name__ == "__main__":
    scan_and_visualize(DATA_DIR, model, transform, num_images=3)

import os
import json
import random
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from matplotlib.gridspec import GridSpec
from torchvision import transforms, models

TREATMENT_RECOMMENDATIONS ={
  "Apple___Apple_scab": [
    "Apply fungicides (captan or sulfur) when leaves first appear.",
    "Rake and destroy fallen leaves to reduce overwintering spores.",
    "Plant resistant apple varieties.",
    "Prune trees to allow sunlight and air circulation."
  ],
  "Apple___Black_rot": [
    "Remove and destroy mummified fruit and dead wood.",
    "Apply fungicides (captan or thiophanate-methyl).",
    "Prune trees to increase airflow and dry foliage faster.",
    "Avoid wounding trees during harvest."
  ],
  "Apple___Cedar_apple_rust": [
    "Remove nearby juniper/cedar trees (alternate hosts) within a 2-mile radius.",
    "Apply fungicides (myclobutanil or sulfur) at the pink bud stage.",
    "Plant resistant apple varieties.",
    "Prune galls from cedar trees if removal isn't possible."
  ],
  "Apple___healthy": [
    "Maintain regular watering and fertilization schedule.",
    "Prune annually to maintain shape and airflow.",
    "Monitor for early signs of pests.",
    "Ensure soil drainage is adequate."
  ],
  "Blueberry___healthy": [
    "Maintain acidic soil (pH 4.5-5.5).",
    "Mulch with pine bark or sawdust to retain moisture.",
    "Ensure consistent watering, especially during fruit set.",
    "Prune older canes to encourage new growth."
  ],
  "Cherry_(including_sour)___Powdery_mildew": [
    "Apply fungicides (sulfur or potassium bicarbonate).",
    "Prune to improve air circulation and light penetration.",
    "Avoid overhead watering to keep foliage dry.",
    "Remove and destroy infected leaves in autumn."
  ],
  "Cherry_(including_sour)___healthy": [
    "Provide full sun and well-draining soil.",
    "Fertilize in early spring.",
    "Prune dead or diseased branches annually.",
    "Protect fruit from birds using netting."
  ],
  "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot": [
    "Rotate crops with non-host plants for at least 2 years.",
    "Plant resistant corn hybrids.",
    "Plow under crop debris to reduce fungus survival.",
    "Apply fungicides (azoxystrobin or pyraclostrobin) if infection is severe."
  ],
  "Corn_(maize)___Common_rust_": [
    "Plant resistant hybrids (most effective method).",
    "Apply fungicides early if pustules appear on lower leaves.",
    "Destroy volunteer corn plants.",
    "Monitor fields closely during cool, moist weather."
  ],
  "Corn_(maize)___Northern_Leaf_Blight": [
    "Plant resistant hybrids.",
    "Rotate crops to reduce inoculum levels.",
    "Apply foliar fungicides during the silking stage.",
    "Manage crop residue by tillage."
  ],
  "Corn_(maize)___healthy": [
    "Ensure adequate nitrogen fertilization.",
    "Control weeds to reduce competition.",
    "Maintain consistent soil moisture.",
    "Monitor for pests like corn earworm."
  ],
  "Grape___Black_rot": [
    "Remove and destroy mummified berries and infected canes.",
    "Apply fungicides (mancozeb or myclobutanil) from bud break to fruit set.",
    "Prune for good air circulation.",
    "Weed underneath vines to increase airflow."
  ],
  "Grape___Esca_(Black_Measles)": [
    "Prune out infected wood well below visible symptoms.",
    "Protect pruning wounds with sealant.",
    "Remove and burn dead vines immediately.",
    "There is no chemical cure; prevention is key."
  ],
  "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)": [
    "Apply fungicides used for other grape diseases (often managed concurrently).",
    "Improve air circulation through pruning.",
    "Maintain vine health through proper fertilization.",
    "Remove debris from the vineyard floor."
  ],
  "Grape___healthy": [
    "Prune annually during dormancy.",
    "Train vines to a trellis system.",
    "Monitor nutrient levels (especially magnesium and iron).",
    "Ensure proper irrigation without waterlogging."
  ],
  "Orange___Haunglongbing_(Citrus_greening)": [
    "There is no cure; remove and destroy infected trees immediately.",
    "Control Asian Citrus Psyllid (the vector) with insecticides.",
    "Use disease-free nursery stock.",
    "Inspect trees regularly for yellowing shoots."
  ],
  "Peach___Bacterial_spot": [
    "Plant resistant varieties.",
    "Apply copper-based sprays during dormancy.",
    "Avoid heavy nitrogen fertilization which promotes susceptible growth.",
    "Maintain plant vigor with proper pruning."
  ],
  "Peach___healthy": [
    "Prune to an open center shape for light penetration.",
    "Thin fruit to improve size and quality.",
    "Apply dormant oil sprays to control scale and mites.",
    "Water deeply during dry spells."
  ],
  "Pepper,_bell___Bacterial_spot": [
    "Use disease-free certified seeds.",
    "Rotate crops (avoid peppers/tomatoes in same spot for 3-4 years).",
    "Apply copper bactericides.",
    "Avoid overhead irrigation."
  ],
  "Pepper,_bell___healthy": [
    "Stake plants to support heavy fruit load.",
    "Maintain consistent moisture to prevent blossom end rot.",
    "Mulch to suppress weeds and retain moisture.",
    "Harvest regularly to encourage production."
  ],
  "Potato___Early_blight": [
    "Apply fungicides (chlorothalonil or mancozeb).",
    "Practice crop rotation.",
    "Keep plants vigorous with adequate nitrogen.",
    "Remove infected lower leaves."
  ],
  "Potato___Late_blight": [
    "Destroy all infected plants immediately (highly contagious).",
    "Apply preventative fungicides.",
    "Use certified disease-free seed potatoes.",
    "Eliminate cull piles and volunteer potatoes."
  ],
  "Potato___healthy": [
    "Hill soil around stems to protect tubers.",
    "Maintain consistent soil moisture.",
    "Monitor for potato beetles.",
    "Harvest after vines have died back."
  ],
  "Raspberry___healthy": [
    "Prune canes that have fruited (floricanes).",
    "Maintain rows to 1-2 feet wide.",
    "Mulch to keep roots cool and moist.",
    "Support canes with a trellis."
  ],
  "Soybean___healthy": [
    "Ensure proper spacing.",
    "Monitor for soybean aphids.",
    "Maintain soil pH between 6.0 and 6.8.",
    "Practice weed management."
  ],
  "Squash___Powdery_mildew": [
    "Apply fungicides (neem oil, sulfur, or potassium bicarbonate).",
    "Plant resistant varieties.",
    "Space plants widely for air circulation.",
    "Water at the base to keep leaves dry."
  ],
  "Strawberry___Leaf_scorch": [
    "Remove and burn infected leaves.",
    "Apply fungicides (captan or copper).",
    "Keep the patch weed-free to reduce moisture.",
    "Renovate beds immediately after harvest."
  ],
  "Strawberry___healthy": [
    "Mulch with straw to keep fruit off the soil.",
    "Remove runners to focus energy on fruit (if desired).",
    "Ensure full sun exposure.",
    "Water 1-2 inches per week."
  ],
  "Tomato___Bacterial_spot": [
    "Remove and destroy infected plants.",
    "Spray with copper fungicides.",
    "Avoid working in wet plants.",
    "Rotate crops for at least 2 years."
  ],
  "Tomato___Early_blight": [
    "Trim off infected lower leaves.",
    "Apply mulch to prevent soil splash.",
    "Stake plants to improve airflow.",
    "Apply fungicide if symptoms persist."
  ],
  "Tomato___Late_blight": [
    "Remove entire infected plant and destroy (do not compost).",
    "Apply copper-based fungicide preventatively.",
    "Water only at the base of the plant.",
    "Ensure wide spacing between plants."
  ],
  "Tomato___Leaf_Mold": [
    "Increase ventilation (crucial in greenhouses).",
    "Apply fungicide (chlorothalonil).",
    "Remove lower leaves to improve airflow.",
    "Reduce humidity levels."
  ],
  "Tomato___Septoria_leaf_spot": [
    "Remove infected leaves immediately.",
    "Apply fungicide (chlorothalonil).",
    "Practice crop rotation.",
    "Clean up all crop debris at end of season."
  ],
  "Tomato___Spider_mites Two-spotted_spider_mite": [
    "Spray with a strong stream of water to dislodge mites.",
    "Apply insecticidal soap or neem oil.",
    "Introduce predatory mites.",
    "Keep plants well-watered (mites love hot, dry conditions)."
  ],
  "Tomato___Target_Spot": [
    "Remove old plant debris.",
    "Apply fungicides (azoxystrobin).",
    "Improve air circulation.",
    "Avoid overhead irrigation."
  ],
  "Tomato___Tomato_Yellow_Leaf_Curl_Virus": [
    "Remove and destroy infected plants immediately.",
    "Control whiteflies (vectors) with sticky traps or sprays.",
    "Use reflective mulches.",
    "Plant resistant varieties (look for 'TY' on labels)."
  ],
  "Tomato___Tomato_mosaic_virus": [
    "Remove infected plants; there is no cure.",
    "Wash hands thoroughly (virus spreads by touch/tobacco).",
    "Disinfect tools with bleach solution.",
    "Control aphids."
  ],
  "Tomato___healthy": [
    "Stake or cage plants for support.",
    "Water deeply and consistently.",
    "Fertilize with tomato-specific fertilizer.",
    "Prune 'suckers' for better fruit production."
  ]

}

def get_model(num_classes, device):
    """
    Creates EfficientNet-B0 architecture to match your training script.
    """
    model = models.efficientnet_b0(weights=None)
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

    return model.to(device)

def get_default_transform():
    """Standard transform for inference"""
    return transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor()
    ])
def interactive_disease_diagnosis(model_path, dataset_dir):

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ Running on {device}")

    if not os.path.exists(dataset_dir):
        print(f"‚ùå Error: Dataset directory '{dataset_dir}' not found.")
        return

    class_names = sorted([d for d in os.listdir(dataset_dir)
                         if os.path.isdir(os.path.join(dataset_dir, d))
                         and not d.startswith('.')])

    num_classes = len(class_names)
    print(f"üìÇ Found {num_classes} disease classes.")

    if num_classes == 0:
        print("‚ùå No classes found. Check dataset path.")
        return

    try:
        model = get_model(num_classes, device)

        if torch.cuda.is_available():
            loaded_data = torch.load(model_path)
        else:
            loaded_data = torch.load(model_path, map_location=torch.device('cpu'))

        if isinstance(loaded_data, dict) and 'state_dict' in loaded_data:
            model.load_state_dict(loaded_data['state_dict'])
        elif isinstance(loaded_data, dict):
             model.load_state_dict(loaded_data)
        else:
            model = loaded_data

        model.eval()
        print("‚úÖ Model loaded successfully.")
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        return

    transform = get_default_transform()

    test_images = []
    for cls in class_names:
        folder_path = os.path.join(dataset_dir, cls)
        images = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if images:
            selected = random.choice(images)
            test_images.append((os.path.join(folder_path, selected), cls))
            
    num_display = min(6, len(test_images))
    if num_display == 0:
        print("‚ùå No images found in dataset folders.")
        return

    selected_samples = random.sample(test_images, num_display)
    plt.rcParams.update({'font.size': 10})
    fig = plt.figure(figsize=(20, 15))
    gs = GridSpec(2, 3, figure=fig)

    fig.suptitle("üåø AI Plant Disease Diagnosis", fontsize=24, fontweight='bold', y=0.98, color='green')

    for i, (img_path, true_label) in enumerate(selected_samples):
        row = i // 3
        col = i % 3
        ax = fig.add_subplot(gs[row, col])

        try:
            img = Image.open(img_path).convert('RGB')
            img_tensor = transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                outputs = model(img_tensor)
                probs = torch.nn.functional.softmax(outputs, dim=1)[0]

            conf, pred_idx = torch.max(probs, 0)
            pred_class = class_names[pred_idx.item()]
            confidence = conf.item() * 100

        except Exception as e:
            print(f"Prediction error on {img_path}: {e}")
            continue

    
        ax.imshow(img)
        ax.axis('off')
        is_correct = (pred_class == true_label)
        status_color = 'green' if is_correct else 'red'

        recs = TREATMENT_RECOMMENDATIONS.get(pred_class,
               TREATMENT_RECOMMENDATIONS.get(pred_class.replace(" ", "_"), ["No specific data."]))

        rec_text = "\n".join([f"‚Ä¢ {r}" for r in recs[:3]])

        title = f"Pred: {pred_class}\nConf: {confidence:.1f}%"
        ax.set_title(title, fontsize=12, fontweight='bold',
                     color='white', bbox=dict(facecolor=status_color, alpha=0.8, boxstyle='round'))

        plt.figtext(
            (col * 0.33) + 0.02,
            (0.53 if row == 0 else 0.05),
            f"TREATMENT:\n{rec_text}",
            fontsize=9, bbox=dict(facecolor='#f0f0f0', alpha=0.9, boxstyle='round')
        )

    plt.tight_layout(rect=[0, 0.1, 1, 0.95])
    plt.show()

if __name__ == "__main__":
    MODEL_FILE = "fast_plant_model.pth"

    DATASET_FOLDER = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid"

    if os.path.exists(MODEL_FILE) and os.path.exists(DATASET_FOLDER):
        interactive_disease_diagnosis(MODEL_FILE, DATASET_FOLDER)
    else:
        print(f"‚ö†Ô∏è Check paths:\nModel exists: {os.path.exists(MODEL_FILE)}\nDataset exists: {os.path.exists(DATASET_FOLDER)}")
